# ğŸ§¬ LabReport Analyzer

LabReport Analyzer is a full-stack project that extracts disease mentions and their severity from unstructured lab report comments using NLP. It stores structured data in a PostgreSQL database and provides REST APIs for interaction.

---

# ğŸŒŸ Features

- ğŸ§  Disease and severity extraction using spaCy  
- ğŸ—ƒï¸ PostgreSQL database for structured storage  
- âš™ï¸ Flask-based backend with REST API  
- ğŸ’» React frontend for visualization and interaction  
- ğŸ§¾ SQL scripts for schema, sample data, and analytics queries  
- ğŸ§ª Includes unit tests using pytest  

---

# ğŸ› ï¸ Tech Stack

- ğŸ Python (Flask)  
- ğŸ§¬ spaCy (NLP)  
- ğŸ—ï¸ SQLAlchemy (ORM)  
- ğŸ˜ PostgreSQL (Database)  
- âš›ï¸ React (Frontend)  
- âœ… Pytest (Testing)  

---

# ğŸ“ Repository Structure

- `app.py` - Flask app entry point  
- `db_schema/` - SQL files: schema, inserts, queries  
- `semantic_analysis/` - NLP logic (spaCy + rules)  
- `test_app.py` - Unit tests for comment API  
- `frontend/` - React frontend 
- `requirements.txt` - Python dependencies  
- `README.md` - Project documentation  

---

# ğŸš€ How to Run the Backend (Flask API)

## ğŸ”§ Step 1: Setup Environment

- Create a virtual environment:
  - `python -m venv venv`
  - `source venv/bin/activate` (Linux/macOS)
  - `venv\Scripts\activate` (Windows)

- Install dependencies:
  - `pip install -r requirements.txt`

## â–¶ï¸ Step 2: Run the Flask Server

- Run the app:
  - `python app.py`
- The API will be available at:
  - `http://127.0.0.1:5000`

## ğŸ§ª Step 3: API Testing

- Use curl, Postman, or browser to test endpoints

---

# ğŸ’» How to Run the Frontend (React)

## ğŸ“‚ Step 1: Navigate to Frontend Directory

- `cd frontend`

## ğŸ“¦ Step 2: Install Dependencies

- `npm install`

## ğŸŸ¢ Step 3: Start Development Server

- `npm start`  
- Open browser at: `http://localhost:5173`

---

# ğŸ“¡ API Endpoints

## âœï¸ Comments CRUD

- `GET /comments` â€“ Retrieve all comments  
- `POST /comments` â€“ Create a new comment  
- `PUT /comments/<id>` â€“ Update an existing comment  
- `DELETE /comments/<id>` â€“ Delete a comment  

## ğŸ“Š NLP & Analytics

- `GET /disease-distribution` â€“ Frequency of diseases  
- `GET /analytics-stats` â€“ Dashboard metrics  
- `GET /comments-analytics` â€“ Comments with NLP annotations  

---

# âœ… Validation Rules

- Comment `text` must not be empty  
- Maximum length: **250 characters**  
- Returns HTTP `400` with error message if invalid  

---

# ğŸ§ª How to Run Tests

- From project root:
  - `pytest test_app.py`

### ğŸ” Test Cases:

- Valid comment creation  
- Rejection of invalid input (empty or too long)  

---

# ğŸ—‚ï¸ PostgreSQL Schema

- Defined in: `db_schema/schema.sql`  
- Includes tables:
  - `patients`  
  - `lab_reports`  
  - `report_items`  
  - `comments`  
  - `disease_analytics`

- Additional SQL files:
  - `db_schema/sample_data.sql` â€“ Sample insertions  
  - `db_schema/queries.sql` â€“ Example analytical queries  

---
# ğŸ“Œ Notes

- Flask server uses *SQLite (in-memory)* by default  
- PostgreSQL schema is available for production setup  
- NLP logic is implemented in semantic_analysis/ using *spaCy* and rule-based logic  
- Frontend consumes the REST API exposedÂ byÂ theÂ backend
- Database schema in `db_schema/schema.sql` â€” load before running app.  
- ORM models defined in `models.py` (SQLAlchemy). 
- Input validation rules in `schema.py` (max 250 chars, non-empty).  
- Unit tests in `test_app.py` (run with `pytest`).  
- Flask entry point: `app.py`.
